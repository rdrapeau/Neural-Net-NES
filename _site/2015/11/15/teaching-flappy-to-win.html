<!DOCTYPE html>
<html>

  <head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <title>Teaching Flappy to Win</title>
  <meta name="description" content="At the end of our last post, we had managed to teach our bird to always flap. This simple goal took us quite a few hours of fiddling with the q learning and ...">

  <link rel="stylesheet" href="/css/main.css">
  <link rel="canonical" href="/2015/11/15/teaching-flappy-to-win.html">
  <link rel="alternate" type="application/rss+xml" title="Deep Q Learning" href="/feed.xml">
</head>


  <body>

    <header class="site-header">

  <div class="wrapper">

    <a class="site-title" href="/">Deep Q Learning</a>

    <img class="bird" src="/assets/bird.png" />
    <nav class="site-nav">
      <a href="#" class="menu-icon">
        <svg viewBox="0 0 18 15">
          <path fill="#424242" d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.031C17.335,0,18,0.665,18,1.484L18,1.484z"/>
          <path fill="#424242" d="M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0c0-0.82,0.665-1.484,1.484-1.484 h15.031C17.335,6.031,18,6.696,18,7.516L18,7.516z"/>
          <path fill="#424242" d="M18,13.516C18,14.335,17.335,15,16.516,15H1.484C0.665,15,0,14.335,0,13.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.031C17.335,12.031,18,12.696,18,13.516L18,13.516z"/>
        </svg>
      </a>

      <div class="trigger">
        
          
        
          
        
          
        
          
          <a class="page-link" href="/milestones/">Project Milestones</a>
          
        
          
          <a class="page-link" href="/posts.html">Blog</a>
          
        
          
        
      </div>
    </nav>

  </div>

</header>


    <div class="page-content">
      <div class="wrapper">
        <article class="post" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title" itemprop="name headline">Teaching Flappy to Win</h1>
    <p class="post-meta"><time datetime="2015-11-15T13:44:40-08:00" itemprop="datePublished">Nov 15, 2015</time></p>
  </header>

  <div class="post-content" itemprop="articleBody">
    <p>At the end of our last post, we had managed to teach our bird to always flap. This simple goal took us quite a few hours of fiddling with the q learning and neural network parameters to realize what was causing it to fail (our state values were too large). Training the bird to beat the game is a much more complicated task that took us many more hours of experimentation. In this post we outline several failures, and a few successes. </p>

<p>We started out by training our bird using the default options set by the ConvnetJS library. The properties are outlined below:</p>

<div class="highlight"><pre><code class="language-js" data-lang="js"><span class="nx">temporal_window</span><span class="o">:</span> <span class="mi">1</span>
<span class="nx">total_learning_steps</span><span class="o">:</span> <span class="mi">100000</span>
<span class="nx">start_learn_threshold</span><span class="o">:</span> <span class="mi">1000</span>
<span class="nx">learning_steps_burnin</span><span class="o">:</span> <span class="mi">3000</span>
<span class="nx">learning_rate</span><span class="o">:</span> <span class="mf">0.01</span>
<span class="nx">epsilon_min</span><span class="o">:</span> <span class="mf">0.05</span>
<span class="nx">gamma</span><span class="o">:</span> <span class="mf">0.8</span></code></pre></div>

<p>We soon realized that we had a data problem. The bird wasnâ€™t getting through the first pipe often enough for it to realize that this was a good thing. The default learning steps burnin was 3000 iterations, which means the number of times it actually made it through the pipe before switching to policy actions (1 - epsilon)% of the time was very low (quite possibly zero). Because our total learning steps was only 100k, the epsilon dropped quickly and the bird was only able to learn that not flapping would cause it to die. Therefore, our bird learned to always flap to the top, and then die once it hit the first pipe. The reward model we were using was:</p>

<div class="highlight"><pre><code class="language-js" data-lang="js"><span class="nx">dead</span><span class="o">:</span> <span class="o">-</span><span class="mi">100</span>
<span class="nx">alive</span><span class="o">:</span> <span class="mi">1</span></code></pre></div>

<p>We tried many reward models and q learning parameters that were slight variations to the ones above, with the same results each time. Flappy only wanted to flap. After a couple days of frustration, we made some breakthroughs. The first was a bug in our state representation. We had been using the absolute value of the delta x and delta y between the bird in the next pipe, but this lost information about whether the bird was below or above the pipe. Fixing this did not solve our problem.</p>

<p>Our next win was an optimization to the game loop. Aaron, our resident Javascript master, was able to increase training speed by an order of magnitude by running multiple iterations of the training for every event loop. This gave us the ability to train much more rapidly and increase the total_learning_steps from ~100-300k to ~1-2m. We still did not see the bird flying through pipes. </p>

<p>We finally got some good learning behavior after rewarding heavily for making it through a pipe and not rewarding at all for being alive. Flying to the top and dying was no longer a good option. The video below shows the bird successfully making it through 47 pipes after being trained with the following parameters:</p>

<p><strong>Brain</strong></p>

<div class="highlight"><pre><code class="language-js" data-lang="js"><span class="nx">temporal_window</span><span class="o">:</span> <span class="mi">3</span>
<span class="nx">total_learning_steps</span><span class="o">:</span> <span class="mi">1000000</span>
<span class="nx">start_learn_threshold</span><span class="o">:</span> <span class="mi">1000</span>
<span class="nx">learning_steps_burnin</span><span class="o">:</span> <span class="mi">50000</span>
<span class="nx">learning_rate</span><span class="o">:</span> <span class="mf">0.01</span>
<span class="nx">epsilon_min</span><span class="o">:</span> <span class="mf">0.05</span>
<span class="nx">gamma</span><span class="o">:</span> <span class="mf">0.7</span>
<span class="kd">var</span> <span class="nx">layer_defs</span> <span class="o">=</span> <span class="p">[</span>
    <span class="p">{</span><span class="nx">type</span><span class="o">:</span><span class="s1">&#39;input&#39;</span><span class="p">,</span> <span class="nx">out_sx</span><span class="o">:</span><span class="mi">1</span><span class="p">,</span> <span class="nx">out_sy</span><span class="o">:</span><span class="mi">1</span><span class="p">,</span> <span class="nx">out_depth</span><span class="o">:</span> <span class="nx">network_size</span><span class="p">},</span>
    <span class="p">{</span><span class="nx">type</span><span class="o">:</span><span class="s1">&#39;fc&#39;</span><span class="p">,</span> <span class="nx">num_neurons</span><span class="o">:</span> <span class="mi">50</span><span class="p">,</span> <span class="nx">activation</span><span class="o">:</span><span class="s1">&#39;relu&#39;</span><span class="p">},</span>
    <span class="p">{</span><span class="nx">type</span><span class="o">:</span><span class="s1">&#39;fc&#39;</span><span class="p">,</span> <span class="nx">num_neurons</span><span class="o">:</span> <span class="mi">50</span><span class="p">,</span> <span class="nx">activation</span><span class="o">:</span><span class="s1">&#39;relu&#39;</span><span class="p">},</span>
    <span class="p">{</span><span class="nx">type</span><span class="o">:</span><span class="s1">&#39;regression&#39;</span><span class="p">,</span> <span class="nx">num_neurons</span><span class="o">:</span><span class="nx">num_actions</span><span class="p">},</span>
<span class="p">]</span></code></pre></div>

<p><strong>State</strong></p>

<div class="highlight"><pre><code class="language-js" data-lang="js"><span class="nx">state</span> <span class="o">=</span> <span class="p">[</span>
    <span class="p">(</span><span class="nx">pipe</span><span class="p">.</span><span class="nx">x</span> <span class="o">-</span> <span class="nx">bird</span><span class="p">.</span><span class="nx">x</span><span class="p">)</span> <span class="o">/</span> <span class="nx">Constants</span><span class="p">.</span><span class="nx">GAME_WIDTH</span><span class="p">,</span>
    <span class="nx">pipe</span><span class="p">.</span><span class="nx">y</span> <span class="o">/</span> <span class="nx">Constants</span><span class="p">.</span><span class="nx">GAME_HEIGHT</span><span class="p">,</span>
    <span class="nx">bird</span><span class="p">.</span><span class="nx">y</span> <span class="o">/</span> <span class="nx">Constants</span><span class="p">.</span><span class="nx">GAME_HEIGHT</span><span class="p">,</span>
<span class="p">]</span></code></pre></div>

<p><strong>Reward</strong></p>

<div class="highlight"><pre><code class="language-js" data-lang="js"><span class="nx">dead</span><span class="o">:</span> <span class="o">-</span><span class="mf">0.5</span>
<span class="nx">just</span> <span class="nx">scored</span><span class="o">:</span> <span class="mi">100</span>
<span class="nx">alive</span><span class="o">:</span> <span class="mi">0</span></code></pre></div>

<iframe width="560" height="315" src="https://www.youtube.com/embed/5U2xCNBmjB0" frameborder="0" allowfullscreen=""></iframe>

<p><strong>Video. 1: We taught it to fly!</strong></p>

<p>The video is sped up to 8x time, because of some rendering inefficiencies.</p>


  </div>

</article>

      </div>
    </div>

    <footer class="site-footer">

  <div class="wrapper">

    <h2 class="footer-heading">Deep Q Learning</h2>

    <div class="footer-col-wrapper">
      <div class="footer-col footer-col-1">
        <ul class="contact-list">
	  <li><a href="https://github.com/rdrapeau">Ryan Drapeau</a></li>
	  <li><a href="https://github.com/sonjakhan">Sonja Khan</a></li>
	  <li><a href="https://github.com/aaronnech">Aaron Nech</a></li>
        </ul>
      </div>

      <div class="footer-col footer-col-2">
        <ul class="social-media-list">
          
          <li>
            <a href="https://github.com/rdrapeau/neural-net-nes"><span class="icon icon--github"><svg viewBox="0 0 16 16"><path fill="#828282" d="M7.999,0.431c-4.285,0-7.76,3.474-7.76,7.761 c0,3.428,2.223,6.337,5.307,7.363c0.388,0.071,0.53-0.168,0.53-0.374c0-0.184-0.007-0.672-0.01-1.32 c-2.159,0.469-2.614-1.04-2.614-1.04c-0.353-0.896-0.862-1.135-0.862-1.135c-0.705-0.481,0.053-0.472,0.053-0.472 c0.779,0.055,1.189,0.8,1.189,0.8c0.692,1.186,1.816,0.843,2.258,0.645c0.071-0.502,0.271-0.843,0.493-1.037 C4.86,11.425,3.049,10.76,3.049,7.786c0-0.847,0.302-1.54,0.799-2.082C3.768,5.507,3.501,4.718,3.924,3.65 c0,0,0.652-0.209,2.134,0.796C6.677,4.273,7.34,4.187,8,4.184c0.659,0.003,1.323,0.089,1.943,0.261 c1.482-1.004,2.132-0.796,2.132-0.796c0.423,1.068,0.157,1.857,0.077,2.054c0.497,0.542,0.798,1.235,0.798,2.082 c0,2.981-1.814,3.637-3.543,3.829c0.279,0.24,0.527,0.713,0.527,1.437c0,1.037-0.01,1.874-0.01,2.129 c0,0.208,0.14,0.449,0.534,0.373c3.081-1.028,5.302-3.935,5.302-7.362C15.76,3.906,12.285,0.431,7.999,0.431z"/></svg>
</span><span class="username">neural-net-nes</span></a>

          </li>
          
        </ul>
      </div>

      <div class="footer-col footer-col-3">
        <p>Project site and blog for CSE571
</p>
      </div>
    </div>

  </div>

</footer>


  </body>

</html>
